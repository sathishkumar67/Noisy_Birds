{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Birddataset(Dataset):\n",
    "    def __init__(self, image_dir: str, allowed_classes: List[str], dataset_type: str = \"train\", do_transform: bool = True):\n",
    "        \"\"\"\n",
    "        Custom dataset class for bird image classification.\n",
    "\n",
    "        Args:\n",
    "            image_dir (str): Path to the root directory containing class subdirectories with images.\n",
    "            allowed_classes (List[str]): List of allowed class names to include.\n",
    "            dataset_type (str): Either \"train\" or \"test\" to control the split of the dataset.\n",
    "            do_transform (bool): Whether to apply transformations to images.\n",
    "\n",
    "        Attributes:\n",
    "            train_samples (List[Tuple[str, str]]): List of training samples as (image_path, class_name) tuples.\n",
    "            test_samples (List[Tuple[str, str]]): List of test samples as (image_path, class_name) tuples.\n",
    "            transform: Transformations to be applied to images.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.allowed_classes = allowed_classes\n",
    "        self.dataset_type = dataset_type\n",
    "        self.do_transform = do_transform\n",
    "\n",
    "        # Predefined image transformations (Normalization for ImageNet-pretrained models)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        # Initialize empty lists for train and test samples\n",
    "        self.train_samples = []\n",
    "        self.test_samples = []\n",
    "\n",
    "        # Preload file paths in parallel for faster processing\n",
    "        self._load_samples()\n",
    "\n",
    "    def _load_samples(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads image file paths and splits them into training and test sets.\n",
    "        Uses multithreading for efficient file scanning.\n",
    "        \"\"\"\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = []\n",
    "\n",
    "            # Iterate over all class directories in the image directory\n",
    "            for class_name in os.listdir(self.image_dir):\n",
    "                class_path = os.path.join(self.image_dir, class_name)\n",
    "                if os.path.isdir(class_path) and (class_name in self.allowed_classes or class_name == \"unlabeled\"):\n",
    "                    futures.append(executor.submit(self._get_class_samples, class_path, class_name))\n",
    "\n",
    "            for future in futures:\n",
    "                class_samples = future.result()\n",
    "\n",
    "                # Separate handling for 'unlabeled' images (assumed to be part of the training set)\n",
    "                if class_samples[0][1] == \"unlabeled\":\n",
    "                    self.train_samples.extend(class_samples)\n",
    "                else:\n",
    "                    # Split samples into training and test sets (80-20 split)\n",
    "                    random.seed(42)\n",
    "                    random.shuffle(class_samples)\n",
    "                    self.train_samples.extend(class_samples[:-3])  # All but last 3 for training\n",
    "                    self.test_samples.extend(class_samples[-3:])   # Last 3 for testing\n",
    "\n",
    "    def _get_class_samples(self, class_dir: str, class_name: str) -> List[Tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        Gets all image file paths for a particular class.\n",
    "\n",
    "        Args:\n",
    "            class_dir (str): Directory path for the class.\n",
    "            class_name (str): Name of the class.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[str, str]]: List of (image_path, class_name) tuples.\n",
    "        \"\"\"\n",
    "        return [(os.path.join(class_dir, img_entry.name), class_name) \n",
    "                for img_entry in os.scandir(class_dir) if img_entry.is_file()]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the total number of images in the dataset split (train or test).\n",
    "\n",
    "        Returns:\n",
    "            int: Length of the dataset split (number of images).\n",
    "        \"\"\"\n",
    "        if self.dataset_type == \"train\":\n",
    "            return len(self.train_samples)\n",
    "        else:\n",
    "            return len(self.test_samples)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"\"\"\n",
    "        Retrieves an image and its corresponding class index from the dataset.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, int]: \n",
    "                - Transformed image tensor.\n",
    "                - Class index corresponding to the image.\n",
    "        \"\"\"\n",
    "        # Select sample based on dataset type\n",
    "        if self.dataset_type == \"train\":\n",
    "            img_path, class_name = self.train_samples[index]\n",
    "        else:\n",
    "            img_path, class_name = self.test_samples[index]\n",
    "\n",
    "        # Lazy loading of the image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations if enabled\n",
    "        if self.do_transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Get the class index from allowed_classes\n",
    "        class_id = self.allowed_classes.index(class_name)\n",
    "\n",
    "        return image, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_config = EncoderConfig(\n",
    "    image_size=128,\n",
    "    hidden_size=512,\n",
    "    intermediate_size=512 * 3,\n",
    "    num_hidden_layers=8,\n",
    "    num_attention_heads=8,\n",
    "    num_channels=3,\n",
    "    patch_size=8,\n",
    "    layer_norm_eps=1e-6,\n",
    "    attention_dropout=0.0,\n",
    "    num_image_tokens=None,\n",
    "    do_random_mask=True,\n",
    "    mask_ratio=0.75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder(encoder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
