{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sathi\\miniconda3\\envs\\dl\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import sys\n",
    "from huggingface_hub import snapshot_download\n",
    "from PIL import Image\n",
    "from typing import Tuple, List\n",
    "import os\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class Birddataset(Dataset):\n",
    "    def __init__(self, image_dir: str, allowed_classes: list, transform=None, dataset_type: str = 'train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (str): Path to the directory containing class subdirectories with images.\n",
    "            allowed_classes (list): List of allowed class names to include.\n",
    "            transform: Transformations to apply to images.\n",
    "            dataset_type (str): Either 'train' or 'test' to control which samples to load.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.allowed_classes = allowed_classes\n",
    "        self.transform = transform\n",
    "        self.dataset_type = dataset_type\n",
    "\n",
    "        # Prepare dataset\n",
    "        self.images = self.prepare_dataset(image_dir, allowed_classes)\n",
    "\n",
    "    def get_class_samples(self, class_dir: str, class_name: str) -> list:\n",
    "        \"\"\"\n",
    "        Get all image file paths for a particular class.\n",
    "\n",
    "        Args:\n",
    "            class_dir (str): Directory of the class.\n",
    "            class_name (str): Name of the class.\n",
    "\n",
    "        Returns:\n",
    "            list: List of (image_path, class_name) tuples.\n",
    "        \"\"\"\n",
    "        return [(os.path.join(class_dir, img_entry.name), class_name) \n",
    "                for img_entry in os.scandir(class_dir) if img_entry.is_file()]\n",
    "\n",
    "    def prepare_dataset(self, image_dir: str, allowed_classes: list) -> list:\n",
    "        \"\"\"\n",
    "        Prepares the dataset by getting paths of images and splitting them into train and test sets.\n",
    "\n",
    "        Args:\n",
    "            image_dir (str): Path to the root directory containing class folders.\n",
    "            allowed_classes (list): List of allowed class names.\n",
    "\n",
    "        Returns:\n",
    "            list: List of (image_path, class_name) tuples.\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "\n",
    "        # Scan directories and process files in parallel\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = []\n",
    "            for class_name in os.listdir(image_dir):\n",
    "                class_path = os.path.join(image_dir, class_name)\n",
    "                if os.path.isdir(class_path) and class_name in allowed_classes:\n",
    "                    futures.append(executor.submit(self.get_class_samples, class_path, class_name))\n",
    "\n",
    "            for future in futures:\n",
    "                class_samples = future.result()\n",
    "                random.seed(42)\n",
    "                random.shuffle(class_samples)\n",
    "                \n",
    "                # Split samples based on dataset type (train or test)\n",
    "                split_idx = int(0.8 * len(class_samples))  # 80-20 train-test split\n",
    "                if self.dataset_type == 'train':\n",
    "                    samples.extend(class_samples[:split_idx])\n",
    "                else:\n",
    "                    samples.extend(class_samples[split_idx:])\n",
    "\n",
    "        # Shuffle final list for randomness\n",
    "        random.seed(42)\n",
    "        random.shuffle(samples)\n",
    "        print(len(samples))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple:\n",
    "        \"\"\"\n",
    "        Retrieves an image and its corresponding class label.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Transformed image tensor and class index.\n",
    "        \"\"\"\n",
    "        image_path, class_name = self.images[index]\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Apply transformation\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Get class index\n",
    "        class_id = self.allowed_classes.index(class_name)\n",
    "\n",
    "        return image, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    }
   ],
   "source": [
    "train_set = Birddataset(\"dataset\",[\"budgie\",\"canary\",\"duckling\",\"rubber duck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a, b \u001b[38;5;241m=\u001b[39m Birddataset\u001b[38;5;241m.\u001b[39mprepare_dataset(\u001b[38;5;28;43mself\u001b[39;49m, image_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m,allowed_classes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbudgie\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcanary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduckling\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrubber duck\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "a, b = Birddataset.prepare_dataset(self, image_dir=\"dataset\",allowed_classes=[\"budgie\",\"canary\",\"duckling\",\"rubber duck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dataset function called\n",
    "class Birddataset(Dataset):\n",
    "    def __init__(self, image_dir: str, allowed_classes: List, transform=None, dataset_type: str = None):\n",
    "        # Initialize paths and transformation\n",
    "        self.image_dir = image_dir\n",
    "        self.allowed_classes = allowed_classes\n",
    "        self.transform = transform\n",
    "        self.dataset_type = dataset_type\n",
    "\n",
    "\n",
    "\n",
    "    def get_class_samples(self, class_dir: str, class_name: str) -> List[Tuple[str, str]]:\n",
    "        # Lazy file reading with os.scandir, which is faster and memory efficient\n",
    "        return [(os.path.join(class_dir, img_entry.name), class_name) \n",
    "                for img_entry in os.scandir(class_dir) if img_entry.is_file()]\n",
    "\n",
    "    def prepare_dataset(self, image_dir: str, allowed_classes: List[str], transform=None) -> Tuple[List[Tuple[str, str]], List[Tuple[str, str]]]:\n",
    "        train_samples = []\n",
    "        test_samples = []\n",
    "\n",
    "        # Scan directories only once\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = []\n",
    "            for class_name in os.listdir(image_dir):\n",
    "                class_path = os.path.join(image_dir, class_name)\n",
    "                if os.path.isdir(class_path) and (class_name in allowed_classes or class_name == \"unlabeled\"):\n",
    "                    # Use thread pool for parallel file processing\n",
    "                    futures.append(executor.submit(self.get_class_samples, class_path, class_name))\n",
    "\n",
    "            for future in futures:\n",
    "                class_samples = future.result()\n",
    "\n",
    "                # Handle 'unlabeled' case separately\n",
    "                if class_samples[0][1] == \"unlabeled\":\n",
    "                    train_samples.extend(class_samples)\n",
    "                else:\n",
    "                    # Split train and test samples\n",
    "                    random.seed(42)\n",
    "                    random.shuffle(class_samples)\n",
    "                    train_samples.extend(class_samples[:-3])\n",
    "                    test_samples.extend(class_samples[-3:])\n",
    "\n",
    "        # Final shuffling of train and test samples\n",
    "        random.seed(42)\n",
    "        random.shuffle(train_samples)\n",
    "        random.shuffle(test_samples)\n",
    "\n",
    "    return train_samples, test_samples\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            int: The total number of image-mask pairs in the designated dataset split.\n",
    "        \"\"\"\n",
    "        # Return the length of the dataset (number of images)\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index of the image-mask pair to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor]: A tuple containing the image and its corresponding one-hot encoded mask.\n",
    "                - image (torch.Tensor): Transformed image tensor.\n",
    "                - onehot_mask (torch.Tensor): One-hot encoded mask tensor for segmentation.\n",
    "        \"\"\"\n",
    "        # # Load the image and mask\n",
    "        # image_path = os.path.join(self.image_dir,self.images[index][1],self.images[index][0])\n",
    "\n",
    "\n",
    "\n",
    "        # # Load image and mask as grayscale\n",
    "        # image = Image.open(image_path)\n",
    "        # if self.transform:\n",
    "        #     transformed = self.transform(image)\n",
    "        # else:\n",
    "        #     transformed = transform_test(image)\n",
    "\n",
    "        # class_id = self.allowed_classes.index(self.images[index][1])\n",
    "\n",
    "        # return transformed, class_id\n",
    "\n",
    "use this one to prepare torch dataset object and use this transform transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "]) prepare in such a way that it is memory and time efficient\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
